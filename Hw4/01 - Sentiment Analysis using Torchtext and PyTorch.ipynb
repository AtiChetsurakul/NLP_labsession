{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Pytorch and Torchtext\n",
    "\n",
    "- bidirectional LSTM on some news\n",
    "- some labeled data on news....\n",
    "\n",
    "- Torchtext to help us numericalize and load some data\n",
    "- Torchtext is backed by PyTorch....so naturally torchtext is quite good\n",
    "- Torchtext is not meant to replace spacy....spacy is still like better in general\n",
    "  \n",
    "- PyTorch to help us make some neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, torchdata, torchtext\n",
    "from torch import nn\n",
    "\n",
    "import time\n",
    "\n",
    "#1. puffer - it's outdated....\n",
    "#2. spend some money - 300 baht get collab pro\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#reproducibility \n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchdata.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "\n",
    "Make our life easy by using some ready-to-be-used dataset by torchtext\n",
    "\n",
    "- in your assignment, i will ask you to use penn treebank....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from torchtext.datasets import AG_NEWS\n",
    "# train, test = AG_NEWS()\n",
    "import pytreebank\n",
    "dataset = pytreebank.load_sst()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA - exploratory data analysis\n",
    "- check common words\n",
    "- look at some random sample....how it looks, so that we can design proper neural network\n",
    "- visualize statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train))  #generator\n",
    "# (“World”, “Sports”, “Business”, “Sci/Tech”)\n",
    "#  1,        2,        3,          4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(iter(train))[100]  #generator\n",
    "# (“World”, “Sports”, “Business”, “Sci/Tech”)\n",
    "#  1,        2,        3,          4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([y for y, x in list(iter(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39miter\u001b[39;49m(train)))\n\u001b[1;32m      2\u001b[0m train_size\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/grouping.py:41\u001b[0m, in \u001b[0;36mShardingFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mfor\u001b[39;00m i, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe):\n\u001b[1;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_id:\n\u001b[1;32m     43\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:124\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[0;32m--> 124\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    125\u001b[0m             \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:167\u001b[0m, in \u001b[0;36m_CSVBaseParserIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[D, Tuple[\u001b[39mstr\u001b[39m, D]]]:\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    168\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[1;32m    169\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mdecode(stream)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:438\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    439\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    440\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/util/hashchecker.py:67\u001b[0m, in \u001b[0;36mHashCheckerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, StreamWrapper]]:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mfor\u001b[39;00m file_name, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     68\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhash_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msha256\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m             hash_func \u001b[39m=\u001b[39m hashlib\u001b[39m.\u001b[39msha256()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/load/online.py:94\u001b[0m, in \u001b[0;36mHTTPReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39myield\u001b[39;00m _get_response_from_http(url, timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_params)\n\u001b[1;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39myield\u001b[39;00m _get_response_from_http(url, timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchdata/datapipes/iter/load/online.py:43\u001b[0m, in \u001b[0;36m_get_response_from_http\u001b[0;34m(url, timeout, **query_params)\u001b[0m\n\u001b[1;32m     41\u001b[0m proxies \u001b[39m=\u001b[39m _get_proxies()\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     r \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mget(url, stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, proxies\u001b[39m=\u001b[39;49mproxies, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mquery_params)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     r \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mget(url, timeout\u001b[39m=\u001b[39mtimeout, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, proxies\u001b[39m=\u001b[39mproxies, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mquery_params)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/requests/sessions.py:542\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[1;32m    536\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i gonna cheat a little bit, not gonna use all...my fans will work too hard....\n",
    "too_much, train, valid = trainset.random_split(total_length=train_size, \n",
    "                                            weights = {\"too_much\": 0.7, \n",
    "                                                       \"smaller_train\": 0.2,\n",
    "                                                       \"valid\": 0.1},\n",
    "                                            seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = len(list(iter(train)))\n",
    "# val_size   = len(list(iter(valid)))\n",
    "# test_size  = len(list(iter(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "1101\n",
      "2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(trainset)), print(len(devset)), print(len(testset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 Tokenizing\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "#check whether the tokenizer works.....\n",
    "# tokens    = tokenizer(\"Chaky likes deep learning very much and wants his \\\n",
    "                    #   student to be number 1 in Asia....\")\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 'Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable LabeledTree object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m data_iter:\n\u001b[1;32m      7\u001b[0m         \u001b[39myield\u001b[39;00m tokenizer(text)\n\u001b[0;32m----> 9\u001b[0m vocab \u001b[39m=\u001b[39m build_vocab_from_iterator(yield_tokens(trainset), specials\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m<unk>\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m<pad>\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m                                                                  \u001b[39m'\u001b[39;49m\u001b[39m<bos>\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m<eos>\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ai50/lib/python3.9/site-packages/torchtext/vocab/vocab_factory.py:98\u001b[0m, in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator, min_freq, specials, special_first, max_tokens)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mBuild a Vocab from an iterator.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m    >>> vocab = build_vocab_from_iterator(yield_tokens(file_path), specials=[\"<unk>\"])\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m counter \u001b[39m=\u001b[39m Counter()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mfor\u001b[39;00m tokens \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m     99\u001b[0m     counter\u001b[39m.\u001b[39mupdate(tokens)\n\u001b[1;32m    101\u001b[0m specials \u001b[39m=\u001b[39m specials \u001b[39mor\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m, in \u001b[0;36myield_tokens\u001b[0;34m(data_iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39myield_tokens\u001b[39m(data_iter):  \u001b[39m#data_iter, e.g., train\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m data_iter:\n\u001b[1;32m      7\u001b[0m         \u001b[39myield\u001b[39;00m tokenizer(text)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable LabeledTree object"
     ]
    }
   ],
   "source": [
    "## 3.2 Numericalization\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens(data_iter):  #data_iter, e.g., train\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainset), specials=['<unk>', '<pad>',\n",
    "                                                                 '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"]) #if you don't the id of this word, set it unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 944, 38, 3956, 8, 43, 498, 109, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['Chaky', 'wants', 'his', 'student', 'to', 'be', 'number', '1', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52686"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)  #52k unique words....."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FastText embedding\n",
    "\n",
    "We gonna insert this embedding to the NN on the fly....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText\n",
    "fast_vectors = FastText(language='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_embedding = fast_vectors.get_vecs_by_tokens(vocab.get_itos()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52686, 300])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_embedding.shape #(vocab size, 300) == (52k, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0935,  0.0915,  0.2640,  0.0387,  0.0843,  0.3809, -0.1776,  0.1745,\n",
       "        -0.0362, -0.0278])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#please lookup the fasttext embedding of id 100\n",
    "fast_embedding[100][:10] #size of 300 dim of this word id 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing dataloader\n",
    "\n",
    "Optional - you can either make your own batch loader....\n",
    "You can use pytorch dataloader...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline  = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1  #1, 2, 3, 4 ---> 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwhy padding????\\n\\nin the same batch, e.g., batch size = 2\\n\\n\"chaky eat sushi\", ==> \"chaky\", \"eat\", \"sushi\" ==> 0, 22, 11, 1, 1\\n\"chaky sleep\" ==> \"chaky\", \"sleep\" ==> 0, 99, 1, 1, 1\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "why padding????\n",
    "\n",
    "in the same batch, e.g., batch size = 2\n",
    "\n",
    "\"chaky eat sushi\", ==> \"chaky\", \"eat\", \"sushi\" ==> 0, 22, 11, 1, 1\n",
    "\"chaky sleep\" ==> \"chaky\", \"sleep\" ==> 0, 99, 1, 1, 1\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence #making each batch same length\n",
    "\n",
    "pad_ix = vocab['<pad>']\n",
    "\n",
    "#this function gonna be called by DataLoader\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, length_list = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        length_list.append(processed_text.size(0)) #for padding\n",
    "        \n",
    "    return torch.tensor(label_list, dtype=torch.int64), \\\n",
    "        pad_sequence(text_list, padding_value=pad_ix, batch_first=True), \\\n",
    "        torch.tensor(length_list, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "val_loader   = DataLoader(valid, batch_size = batch_size,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "test_loader  = DataLoader(test, batch_size = batch_size,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label, text, length in train_loader:\n",
    "#     break\n",
    "\n",
    "#label: [batch size, ]\n",
    "#text : [batch size, longest length of this batch] ==> [batch size, seq len] ==> [b, l]\n",
    "#length:[batch size, ]\n",
    "\n",
    "# label, text, length  #why we need length --> we can later ignore padding...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Designing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers, bidirectional, dropout):\n",
    "        #input dim = how many vocab you have\n",
    "        #emb dim = 300 --> we use fasttext\n",
    "        #padding_idx tells this lookup table to ignore, and just randomize....\n",
    "        #<unk>, <bos>, <eos>\n",
    "        self.embedding_layer = nn.Embedding(input_dim, emb_dim, padding_idx=pad_ix)\n",
    "        self.lstm            = nn.LSTM(emb_dim,\n",
    "                                       hid_dim,\n",
    "                                       num_layers = num_layers,\n",
    "                                       bidrectional = bidirectional,\n",
    "                                       dropout = dropout,  #dropout is applied between layers....\n",
    "                                       batch_first=True)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        #x: [batch size, seq len]\n",
    "        \n",
    "        embedded_x = self.embedding_layer(x)\n",
    "        #x: [batch size, seq len, emb dim]\n",
    "        \n",
    "        #pack this embedded_x in such a way that RNN knows to ignore padding....\n",
    "        #without batch_first = True; things will become [seq len, batch size, emb dim]\n",
    "        pack_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x, lengths.to('cpu'),\n",
    "                                                          enforce_sorted=False,\n",
    "                                                          batch_first = True\n",
    "                                                          )\n",
    "        \n",
    "        #packed_outputs is basically all hidden states\n",
    "        #h is the last hidden state\n",
    "        #c is the last cell state\n",
    "        packed_outputs, (h, c) = self.lstm(pack_embedded)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da867d72de60a3e86a2b69a9a7baea090d67382d01a73f765a7401ae7e7cc0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
