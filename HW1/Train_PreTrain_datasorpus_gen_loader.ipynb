{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import math\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4193\n",
      "[\"there's\", 'gaetan', \"d'amours\", 'who', 'is', 'our', 'newest', 'mr.', 'canada', ';', ';']\n",
      "5819\n"
     ]
    }
   ],
   "source": [
    "# corpus = [sent.lower().split(\" \") for sent in corpus]\n",
    "# corpus\n",
    "\n",
    "print(len(brown.sents(categories=['hobbies'])))\n",
    "## too much, to lazy\n",
    "corpus_tokenize_ati_made_cannotdel_canu_haha = brown.sents(categories=['hobbies'])[:1500]\n",
    "# print(corpus_tokenize_ati_made_cannotdel_canu_haha[-10])\n",
    "corpus = [[j.lower() for j in i] for i in corpus_tokenize_ati_made_cannotdel_canu_haha]\n",
    "\n",
    "print(corpus[10])\n",
    "#get word sequences and unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "vocab = list(set(flatten(corpus)))\n",
    "# vocab\n",
    "#numericalization\n",
    "word2index = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "voc_size = len(vocab)\n",
    "\n",
    "print(voc_size)\n",
    "\n",
    "\n",
    "# print(word2index)\n",
    "#append UNK\n",
    "vocab.append('<UNK>')\n",
    "\n",
    "word2index['<UNK>'] = len(word2index)\n",
    "\n",
    "index2word = {v:k for k, v in word2index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('wordtotrain_use.atikeep','wb') as pic:\n",
    "    pickle.dump((corpus,vocab,word2index,index2word),pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da867d72de60a3e86a2b69a9a7baea090d67382d01a73f765a7401ae7e7cc0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
