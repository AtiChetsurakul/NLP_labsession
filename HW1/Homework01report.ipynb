{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# homework 1 report\n",
    "\n",
    "\n",
    "## Implementer : ati\n",
    "\n",
    "\n",
    "inspired from [Tonson](https://github.com/TonsonP), [Todsavad](https://github.com/guntsvzz) ,  [Teacher](https://github.com/chaklam-silpasuwanchai) and Prof amanda\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Import\n",
    "from modulenl import GloVe\n",
    "from modulenl import SkipgramNegSampling\n",
    "from modulenl import Skipgram\n",
    "from modulenl import CBOW\n",
    "from eval_wordy import *\n",
    "from simi_corea import *\n",
    "# Lib/ Framwork import\n",
    "\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import math\n",
    "from itertools import combinations_with_replacement\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics import mean_squared_error as mNE\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## py script describe\n",
    "- all model template can be found in `modulenl.py`.\n",
    "- to preserve all index of vocab `data_opt_ati_brown.py` was once use and all train are using this same corpus and index.\n",
    "- `eval data_pick.py` is used for getting the testset which we store in pickle file for ease of use.\n",
    "- `eval wordy.py` store all function for calculate the accuracy.\n",
    "- `simi_corea.py` store function to load similarity dataset and also a function for find a correation value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordtotrain_use.atikeep','rb') as pic:\n",
    "    corpus,vocab,word2index,index2word = pickle.load(pic)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "voc_size = len(vocab)\n",
    "with open('data_to_test.atikeep','rb') as dic:\n",
    "    test_set = pickle.load(dic)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus component\n",
    "- brown.sents(categories=['hobbies'])[:1500] From NLTK\n",
    "    - To see more please visit `Train_PreTrain_datasorpus_gen_load.ipynb` or `data_opt_brown.py`\n",
    "\n",
    "#### test set component\n",
    "- family: 20\n",
    "\n",
    "- gram2 Opposite : 20\n",
    "\n",
    "- gram3 Comparative :20\n",
    "\n",
    "- gram4 Superlative : 20\n",
    "\n",
    "- gram8 Plural : 70\n",
    "\n",
    "### Total 150 test sample\n",
    "- For more, please visit `eval_datapick.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myhobglove.atikeep','rb') as dic:\n",
    "    gov_model = pickle.load(dic)\n",
    "\n",
    "with open('myhob_C_Bro.atikeep','rb') as dic:\n",
    "    cBro_model = pickle.load(dic)\n",
    "\n",
    "with open('myhobskp_normal.atikeep','rb') as dic:\n",
    "    skp_model = pickle.load(dic)\n",
    "\n",
    "with open('myhobskpneg.atikeep','rb') as dic:\n",
    "    neg_skp_model = pickle.load(dic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Method\n",
    "- Accuracy for both semantic and syntatic.\n",
    "    - the semantic acc are calculate from 130 test sample with opposite, comparative,superlative and plural grammar.\n",
    "    - On the other hand, semantic acc are calculate from 20 sample with the word relate to family. \n",
    "- Similarity score test\n",
    "    - we can calculate the correlation of 2 metrix with ` Spearman correlation coefficient`\n",
    "    - though it give us corr from score -1,1 but our range is 1,10 so we perform normalization of correlation as follow eq.\n",
    "$$ zi = (xi – min(x)) / (max(x) – min(x)) $$\n",
    "--------------\n",
    "## Result \n",
    "### Glove result\n",
    "``` python\n",
    "Epoch: 1000 | cost: 16.179327 | time: -0.018680095672607422s\n",
    "Epoch: 2000 | cost: 16.347530 | time: -0.017574310302734375s\n",
    "Epoch: 3000 | cost: 1.635131 | time: -0.01890087127685547s\n",
    "Epoch: 4000 | cost: 1.975415 | time: -0.03319716453552246s\n",
    "Epoch: 5000 | cost: 3.769938 | time: -0.021063804626464844s\n",
    "end loss = 3.769937515258789 + with time = 104.4947772026062 \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic and syntatic Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Glove method with Brown corpus is 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_gove = analogy_accuracy(test_set, vocab, get_embed_test, word2index, gov_model)\n",
    "\n",
    "print(f'Accuracy of Glove method with Brown corpus is {acc_gove*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean square error of similarity point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.347199999999994\n"
     ]
    }
   ],
   "source": [
    "simi_score_gov = [[(call_score(get_embed_test(w1,word2index,gov_model),get_embed_test(w2,word2index,gov_model))+10)/2,float(scor)] for w1,w2,scor in semi_get_data('data/wordsim_similarity_goldstandard.txt')]\n",
    "govmappe = mNE(simi_score_gov[-1],simi_score_gov[0])\n",
    "print(govmappe)#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## negative sampling skipgram\n",
    "``` python\n",
    "Epoch: 1000 | cost: 9.851048 | time: 0m 0s\n",
    "Epoch: 2000 | cost: 8.355739 | time: 0m 0s\n",
    "Epoch: 3000 | cost: 7.831168 | time: 0m 0s\n",
    "Epoch: 4000 | cost: 10.446352 | time: 0m 0s\n",
    "Epoch: 5000 | cost: 8.289867 | time: 0m 0s\n",
    "\n",
    "ESt time = 8 min 3.5 sec\n",
    "```\n",
    " ### semantic and syntatic acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SkipGram with negative sampling method with Brown corpus is 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_neg = analogy_accuracy(test_set, vocab, get_embed_test, word2index, neg_skp_model)\n",
    "\n",
    "print(f'Accuracy of SkipGram with negative sampling method with Brown corpus is {acc_neg*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean square error of similarity point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.34719999999999\n"
     ]
    }
   ],
   "source": [
    "simi_score_neggram = [[(call_score(get_embed_test(w1,word2index,neg_skp_model),get_embed_test(w2,word2index,neg_skp_model))+10)/2,float(scor)] for w1,w2,scor in semi_get_data('data/wordsim_similarity_goldstandard.txt')]\n",
    "negmappe = mNE(simi_score_neggram[-1] ,simi_score_neggram[0])\n",
    "print(negmappe)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram\n",
    "``` python\n",
    "Epoch: 1000 | cost: 8.582491 | time: 0m 0s\n",
    "Epoch: 2000 | cost: 9.056213 | time: 0m 0s\n",
    "Epoch: 3000 | cost: 9.070553 | time: 0m 0s\n",
    "Epoch: 4000 | cost: 10.536556 | time: 0m 0s\n",
    "Epoch: 5000 | cost: 8.487428 | time: 0m 0s\n",
    "```\n",
    "Est time = 7 min 39 sec\n",
    "\n",
    "### semantic and syntatic acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of skipGram method with Brown corpus is 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_skp = analogy_accuracy(test_set, vocab, get_embed_test, word2index, skp_model)\n",
    "\n",
    "print(f'Accuracy of skipGram method with Brown corpus is {acc_skp*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean square error of similarity point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.347199999999994\n"
     ]
    }
   ],
   "source": [
    "simi_score_skp = [[(call_score(get_embed_test(w1,word2index,skp_model),get_embed_test(w2,word2index,skp_model))+10)/2,float(scor)] for w1,w2,scor in semi_get_data('data/wordsim_similarity_goldstandard.txt')]\n",
    "skpmappe = mNE(simi_score_skp[-1],simi_score_skp[0])\n",
    "print(skpmappe)#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBow\n",
    "```python\n",
    "Epoch: 100 | cost: 11.299652 | time: 17.72466206550598\n",
    "Epoch: 200 | cost: 10.979570 | time: 35.26954507827759\n",
    "Epoch: 300 | cost: 11.599943 | time: 55.95752930641174\n",
    "Epoch: 400 | cost: 11.446724 | time: 75.82228302955627\n",
    "Epoch: 500 | cost: 11.278444 | time: 94.97708511352539\n",
    "EstTime = 1 min 36 sec**\n",
    "```\n",
    "### semantic and syntatic acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBOW method with Brown corpus is 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_cBro = analogy_accuracy(test_set, vocab, get_embed_test_c_Bro, word2index, cBro_model)\n",
    "\n",
    "print(f'Accuracy of CBOW method with Brown corpus is {acc_cBro*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean square error of similarity point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.34719999999999\n"
     ]
    }
   ],
   "source": [
    "simi_score_cbro = [[(call_score(get_embed_test_c_Bro(w1,word2index,cBro_model),get_embed_test_c_Bro(w2,word2index,cBro_model))+10)/2,float(scor)] for w1,w2,scor in semi_get_data('data/wordsim_similarity_goldstandard.txt')]\n",
    "cbromappe = mNE(simi_score_cbro[-1],simi_score_cbro[0])\n",
    "print(cbromappe)#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim trained version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.50d.txt')\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birds\n"
     ]
    }
   ],
   "source": [
    "predict = model.most_similar(positive=['bird', 'bananas'], negative=['banana'])[0][0]\n",
    "# banana bananas bird birds\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count by categories [13, 1, 6, 5, 47]\n",
      "accuracy by categories = [65.          5.         30.         25.         67.14285714]\n",
      "Accuracy of Gensim pretrian model is 48.0\n"
     ]
    }
   ],
   "source": [
    "genss,cateCorr = analogy_accuracy_(test_set,model)\n",
    "\n",
    "print(f'accuracy by categories = {np.array(cateCorr)/ np.array([20,20,20,20,70]) * 100}')\n",
    "print(f'Accuracy of Gensim pretrian model is {genss*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All categories for test\n",
    "- family\n",
    "- gram2 Opposite\n",
    "- gram3 Comparative\n",
    "- gram4 Superlative \n",
    "- gram8 Plural"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model method    | time          | all accuracy | Syntactic acc | Semantic accuracy | Similarity Score Error  | is_Learn |\n",
    "|-----------------|---------------|--------------|---------------|-------------------|-------------------------|----------|\n",
    "| GloVe           | 1 min 45 sec  | 0            | 0             | 0                 | 25.347199999999994      | Yes      |\n",
    "| NegsamskipGram  | 8 min 3.5 sec | 0            | 0             | 0                 | 75.34719999999999       | No       |\n",
    "| SkipGram        | 7 min 39 sec  | 0            | 0             | 0                 | 25.347199999999994      | No       |\n",
    "| CBOW            | 16 min **     | 0            | 0             | 0                 | 75.34719999999999       | No       |\n",
    "| Gensim_Pretrain | -             | 48           | 45.38         | 65                | -                       | -        |\n",
    "\n",
    "\n",
    "\n",
    " - ** CBOW training time are calculate by forward estimation 10 fold since I did not wait to get the result \n",
    " - *2 Accuracy was calculate by `most_similar` method to match the test set that TA.Amanda provided\n",
    "    - Method of accuracy is using the top 1 similar check by match.\n",
    "- To shorten to training time, `windowsize =1` is used for all build from stratch\n",
    "- embsize = 2 for our 4 model\n",
    "- Negative sampling No. = 3\n",
    "\n",
    "- **Important note**\n",
    "    - the semantic acc are calculate from 130 test sample with opposite, comparative,superlative and plural grammar.\n",
    "    - On the other hand, semantic acc are calculate from 20 sample with the word relate to family. \n",
    "- Since the train dataset is quite small so we do cheate a bit on pick some easy test category.\n",
    "\n",
    "# Inference\n",
    "- accuracy and similarity score\n",
    "    - we observe 0 accuracy from training with a small size of corpus ( ~4000 sentence) and really bad error in similarity test\n",
    "    - since we use small corpus, small window size , and personally, small embed size ( = 2) result are not good.\n",
    "- Training time are fastest on glove and CBOW is the slowest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Ref\n",
    "R. Řehůřek and P. Sojka, ‘Software Framework for Topic Modelling with Large Corpora’, in Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, 2010, pp. 45–50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da867d72de60a3e86a2b69a9a7baea090d67382d01a73f765a7401ae7e7cc0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
